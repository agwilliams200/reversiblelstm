{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZUpzSqLgbDH",
        "outputId": "bfa7806a-0e42-410a-e6be-00d8d3893824"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Folder '/content/drive/MyDrive/Neural Networks final' found!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import os\n",
        "\n",
        "path = '/content/drive/MyDrive/Neural Networks final'\n",
        "\n",
        "if os.path.exists(path):\n",
        "    print(f\"Folder '{path}' found!\")\n",
        "else:\n",
        "    print(f\"Folder '{path}' not found. Please check the path.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3p4mhe92ktfe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "R6qzHmhpkENy"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(f\"{path}/CP_Weather.csv\", encoding=\"latin1\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IimSZZAFBdn"
      },
      "source": [
        "Standard LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Na00sjNf6Jw"
      },
      "source": [
        "First, we tried a standard LSTM using the PyTorch LSTM Module to get a baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4bILwklFA-n",
        "outputId": "69707da0-3476-493f-d392-02976d58cbd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StandardWeatherPredictor(\n",
            "  (lstm): LSTM(5, 16, batch_first=True)\n",
            "  (fc): Linear(in_features=16, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class StandardWeatherPredictor(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(StandardWeatherPredictor, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=1, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        last_output = out[:, -1, :]\n",
        "        output = self.fc(last_output)\n",
        "        return output\n",
        "\n",
        "#test usage\n",
        "input_size = 5\n",
        "hidden_size = 16\n",
        "output_size = 4\n",
        "\n",
        "standard_model = StandardWeatherPredictor(input_size, hidden_size, output_size)\n",
        "print(standard_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ip5rzpnlFRVQ",
        "outputId": "8e9e114f-823f-44c1-d572-81b90da9a598"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50 -- Train Loss: 0.8967\n",
            "Epoch 2/50 -- Train Loss: 0.4576\n",
            "Epoch 3/50 -- Train Loss: 0.2290\n",
            "Epoch 4/50 -- Train Loss: 0.2097\n",
            "Epoch 5/50 -- Train Loss: 0.2076\n",
            "Epoch 6/50 -- Train Loss: 0.2073\n",
            "Epoch 7/50 -- Train Loss: 0.2068\n",
            "Epoch 8/50 -- Train Loss: 0.2064\n",
            "Epoch 9/50 -- Train Loss: 0.2056\n",
            "Epoch 10/50 -- Train Loss: 0.2057\n",
            "Epoch 11/50 -- Train Loss: 0.2053\n",
            "Epoch 12/50 -- Train Loss: 0.2047\n",
            "Epoch 13/50 -- Train Loss: 0.2055\n",
            "Epoch 14/50 -- Train Loss: 0.2046\n",
            "Epoch 15/50 -- Train Loss: 0.2047\n",
            "Epoch 16/50 -- Train Loss: 0.2045\n",
            "Epoch 17/50 -- Train Loss: 0.2042\n",
            "Epoch 18/50 -- Train Loss: 0.2041\n",
            "Epoch 19/50 -- Train Loss: 0.2043\n",
            "Epoch 20/50 -- Train Loss: 0.2039\n",
            "Epoch 21/50 -- Train Loss: 0.2041\n",
            "Epoch 22/50 -- Train Loss: 0.2039\n",
            "Epoch 23/50 -- Train Loss: 0.2035\n",
            "Epoch 24/50 -- Train Loss: 0.2036\n",
            "Epoch 25/50 -- Train Loss: 0.2033\n",
            "Epoch 26/50 -- Train Loss: 0.2034\n",
            "Epoch 27/50 -- Train Loss: 0.2034\n",
            "Epoch 28/50 -- Train Loss: 0.2029\n",
            "Epoch 29/50 -- Train Loss: 0.2025\n",
            "Epoch 30/50 -- Train Loss: 0.2029\n",
            "Epoch 31/50 -- Train Loss: 0.2028\n",
            "Epoch 32/50 -- Train Loss: 0.2024\n",
            "Epoch 33/50 -- Train Loss: 0.2022\n",
            "Epoch 34/50 -- Train Loss: 0.2023\n",
            "Epoch 35/50 -- Train Loss: 0.2019\n",
            "Epoch 36/50 -- Train Loss: 0.2021\n",
            "Epoch 37/50 -- Train Loss: 0.2018\n",
            "Epoch 38/50 -- Train Loss: 0.2015\n",
            "Epoch 39/50 -- Train Loss: 0.2017\n",
            "Epoch 40/50 -- Train Loss: 0.2015\n",
            "Epoch 41/50 -- Train Loss: 0.2015\n",
            "Epoch 42/50 -- Train Loss: 0.2011\n",
            "Epoch 43/50 -- Train Loss: 0.2011\n",
            "Epoch 44/50 -- Train Loss: 0.2006\n",
            "Epoch 45/50 -- Train Loss: 0.2008\n",
            "Epoch 46/50 -- Train Loss: 0.2008\n",
            "Epoch 47/50 -- Train Loss: 0.2006\n",
            "Epoch 48/50 -- Train Loss: 0.2006\n",
            "Epoch 49/50 -- Train Loss: 0.2002\n",
            "Epoch 50/50 -- Train Loss: 0.2004\n",
            "Test Loss: 0.1996\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "dataset['STATION'] = dataset['STATION'].astype('category').cat.codes\n",
        "dataset['NAME'] = dataset['NAME'].astype('category').cat.codes\n",
        "\n",
        "features = dataset[['STATION', 'NAME', 'YEAR', 'MONTH', 'DAY']].values\n",
        "targets  = dataset[['TMAX', 'TMIN']].values\n",
        "\n",
        "\n",
        "features_train, features_test, targets_train, targets_test = train_test_split(\n",
        "    features, targets, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "feat_scaler = StandardScaler()\n",
        "target_scaler = StandardScaler()\n",
        "\n",
        "features_train_scaled = feat_scaler.fit_transform(features_train)\n",
        "targets_train_scaled  = target_scaler.fit_transform(targets_train)\n",
        "\n",
        "features_test_scaled = feat_scaler.transform(features_test)\n",
        "targets_test_scaled  = target_scaler.transform(targets_test)\n",
        "\n",
        "\n",
        "def create_sequences(features, targets, seq_len):\n",
        "    X_seq = []\n",
        "    y_seq = []\n",
        "\n",
        "    for i in range(len(features) - seq_len + 1):\n",
        "        X_seq.append(features[i:i+seq_len])\n",
        "        y_seq.append(targets[i+seq_len-1])\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "seq_len = 10\n",
        "\n",
        "X_train_seq, y_train_seq = create_sequences(features_train_scaled, targets_train_scaled, seq_len)\n",
        "X_test_seq, y_test_seq   = create_sequences(features_test_scaled, targets_test_scaled, seq_len)\n",
        "\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train_seq, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train_seq, dtype=torch.float32)\n",
        "X_test_tensor  = torch.tensor(X_test_seq, dtype=torch.float32)\n",
        "y_test_tensor  = torch.tensor(y_test_seq, dtype=torch.float32)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset  = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader  = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader   = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "model = StandardWeatherPredictor(input_size=5, hidden_size=16, output_size=2)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(x_batch)\n",
        "        loss = criterion(predictions, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * x_batch.size(0)\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} -- Train Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "with torch.no_grad():\n",
        "    for x_batch, y_batch in test_loader:\n",
        "        predictions = model(x_batch)\n",
        "        loss = criterion(predictions, y_batch)\n",
        "        test_loss += loss.item() * x_batch.size(0)\n",
        "test_loss /= len(test_dataset)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTZOms4hGVzQ",
        "outputId": "9f4aa66a-2e93-4d72-a73a-1e35c4abe621"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test MSE Loss: 0.1996\n",
            "Target 0 -- Accuracy: 0.8859, F1 Score: 0.8897\n",
            "Target 1 -- Accuracy: 0.9097, F1 Score: 0.9121\n",
            "Sample Predictions: tensor([[-0.5938, -0.6882],\n",
            "        [ 1.1420,  1.1843],\n",
            "        [-1.2040, -1.2744],\n",
            "        [-1.3801, -1.4245],\n",
            "        [ 0.8012,  0.7940]])\n",
            "Ground Truth: tensor([[-0.1491, -0.2002],\n",
            "        [ 0.9251,  1.4352],\n",
            "        [-1.9583, -2.0779],\n",
            "        [-1.6756, -1.7750],\n",
            "        [ 0.8120,  1.0112]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "\n",
        "y_train = train_dataset.tensors[1]\n",
        "\n",
        "thresholds = torch.median(y_train, dim=0).values\n",
        "\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "all_preds = []\n",
        "all_true = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x_batch, y_batch in test_loader:\n",
        "        predictions = model(x_batch)\n",
        "        loss = criterion(predictions, y_batch)\n",
        "        test_loss += loss.item() * x_batch.size(0)\n",
        "        all_preds.append(predictions)\n",
        "        all_true.append(y_batch)\n",
        "\n",
        "average_test_loss = test_loss / len(test_loader.dataset)\n",
        "print(f\"Test MSE Loss: {average_test_loss:.4f}\")\n",
        "\n",
        "all_preds = torch.cat(all_preds, dim=0)\n",
        "all_true = torch.cat(all_true, dim=0)\n",
        "\n",
        "pred_labels = (all_preds > thresholds).int().cpu().numpy()\n",
        "true_labels = (all_true > thresholds).int().cpu().numpy()\n",
        "\n",
        "accuracies = []\n",
        "f1_scores = []\n",
        "\n",
        "for i in range(2):\n",
        "    acc = accuracy_score(true_labels[:, i], pred_labels[:, i])\n",
        "    f1 = f1_score(true_labels[:, i], pred_labels[:, i])\n",
        "    accuracies.append(acc)\n",
        "    f1_scores.append(f1)\n",
        "    print(f\"Target {i} -- Accuracy: {acc:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x_batch, y_batch in test_loader:\n",
        "        predictions = model(x_batch)\n",
        "        print(\"Sample Predictions:\", predictions[:5])\n",
        "        print(\"Ground Truth:\", y_batch[:5])\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_5owE-GgLwl"
      },
      "source": [
        "These were our baseline accuracy + F1 scores for the standard LSTM. Accuracy is computed using a somewhat arbitrary threshold since we're predicting continuous values, so the loss is in some ways more informative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeU0fyioHg_L"
      },
      "source": [
        "Reversible LSTM + Reversibility Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suNSuFkegkh-"
      },
      "source": [
        "Our basic idea was to split the hidden and cell states into halves, as is often done in reversible architectures, such that one can be computed from the other, allowing us to reverse computations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MNju8K1qFXrw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def leaky_relu_inverse(y, negative_slope=0.01):\n",
        "    return torch.where(y >= 0, y, y / negative_slope)\n",
        "\n",
        "class ReversibleLSTMCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(ReversibleLSTMCell, self).__init__()\n",
        "        assert hidden_size % 2 == 0, \"hidden_size must be even\"\n",
        "        self.hidden_size = hidden_size\n",
        "        half = hidden_size // 2\n",
        "\n",
        "        self.i1 = nn.Linear(input_size + half, half)\n",
        "        self.f1 = nn.Linear(input_size + half, half)\n",
        "        self.o1 = nn.Linear(input_size + half, half)\n",
        "        self.g1 = nn.Linear(input_size + half, half)\n",
        "\n",
        "        self.i2 = nn.Linear(input_size + half, half)\n",
        "        self.f2 = nn.Linear(input_size + half, half)\n",
        "        self.o2 = nn.Linear(input_size + half, half)\n",
        "        self.g2 = nn.Linear(input_size + half, half)\n",
        "\n",
        "    def forward(self, x, h, c):\n",
        "        half = self.hidden_size // 2\n",
        "        h1, h2 = h[:, :half], h[:, half:]\n",
        "        c1, c2 = c[:, :half], c[:, half:]\n",
        "\n",
        "        combined1 = torch.cat([x, h2], dim=1)\n",
        "        i1 = F.leaky_relu(self.i1(combined1))\n",
        "        f1 = F.softplus(self.f1(combined1)) + 0.1\n",
        "        o1 = F.leaky_relu(self.o1(combined1))\n",
        "        g1 = F.leaky_relu(self.g1(combined1))\n",
        "        c1_new = f1 * c1 + i1 * g1\n",
        "        #here is the issue-- multiplication massively amplifies differences...\n",
        "        h1_new = o1 * F.leaky_relu(c1_new)\n",
        "\n",
        "        combined2 = torch.cat([x, h1_new], dim=1)\n",
        "        i2 = F.leaky_relu(self.i2(combined2))\n",
        "        f2 = F.softplus(self.f2(combined2)) + 0.1\n",
        "        o2 = F.leaky_relu(self.o2(combined2))\n",
        "        g2 = F.leaky_relu(self.g2(combined2))\n",
        "        c2_new = f2 * c2 + i2 * g2\n",
        "        h2_new = o2 * F.leaky_relu(c2_new)\n",
        "\n",
        "        new_h = torch.cat([h1_new, h2_new], dim=1)\n",
        "        new_c = torch.cat([c1_new, c2_new], dim=1)\n",
        "        return new_h, new_c\n",
        "\n",
        "\n",
        "    def reverse(self, x, new_h, new_c):\n",
        "        half = self.hidden_size // 2\n",
        "        h1_new, h2_new = new_h[:, :half], new_h[:, half:]\n",
        "        c1_new, c2_new = new_c[:, :half], new_c[:, half:]\n",
        "        combined2 = torch.cat([x, h1_new], dim=1)\n",
        "        i2 = F.leaky_relu(self.i2(combined2))\n",
        "        f2 = F.softplus(self.f2(combined2)) + 0.1\n",
        "        o2 = F.leaky_relu(self.o2(combined2))\n",
        "        g2 = F.leaky_relu(self.g2(combined2))\n",
        "        c2 = (c2_new - i2 * g2) / f2\n",
        "        #any small diffs in cell state are amplified by leaky relu nonlinearity\n",
        "        #inherently this is gonna be worse than recovering the cell state because h_new does not use h in its computation\n",
        "        #this means we have to compute it from c_recovered, whereas c_recovered can be computed from c_new\n",
        "        #so any errors in c_recovered computation massively propagate into h_recovered\n",
        "        h2 = o2 * F.leaky_relu(c2)\n",
        "\n",
        "        combined1 = torch.cat([x, h2], dim=1)\n",
        "        i1 = F.leaky_relu(self.i1(combined1))\n",
        "        f1 = F.softplus(self.f1(combined1)) + 0.1\n",
        "        o1 = F.leaky_relu(self.o1(combined1))\n",
        "        g1 = F.leaky_relu(self.g1(combined1))\n",
        "        c1 = (c1_new - i1 * g1) / f1\n",
        "        h1 = o1 * F.leaky_relu(c1)\n",
        "\n",
        "        h = torch.cat([h1, h2], dim=1)\n",
        "        c = torch.cat([c1, c2], dim=1)\n",
        "        return h, c\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpb08QXQg4gW"
      },
      "source": [
        "Additionally, we replaced all sigmoid + tanh activations with leaky ReLu, since sigmoid and tanh are saturating nonlinearities, meaning that they're inherently less easily reversible than something that's piecewise linear like leaky ReLu. We found that this improved reversibility by a significant amount. Leaky ReLu, as oppposed to regular ReLu, was also crucial here because it helped mitigate entering the ReLu dead zone, which was definitely going to be a problem if we had a ton of regular ReLu activations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Er4w1-hJLSar"
      },
      "outputs": [],
      "source": [
        "class WeatherPredictor(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size=2):\n",
        "        super(WeatherPredictor, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rev_cell = ReversibleLSTMCell(input_size, hidden_size)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "        h = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
        "        c = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
        "        for t in range(seq_len):\n",
        "            h, c = self.rev_cell(x[:, t, :], h, c)\n",
        "        out = self.fc(h)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVYFkBfkheDM"
      },
      "source": [
        "We trained only on the min/max temperature data to limit the scope of the project and allow us to focus more on the actual reversibility of the architecture without having to account for so many varied performance targets. We found that sequence length for the chunks that we split the dataset into had little effect, so we just left it at 10. Obviously, we needed sequential data chunks here in order to harness the memory component of an LSTM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy0OqsroG-cS",
        "outputId": "ceb610d0-cdb1-468c-b0a9-52baf993262e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50 -- Train Loss: 0.8843\n",
            "Epoch 2/50 -- Train Loss: 0.6029\n",
            "Epoch 3/50 -- Train Loss: 0.5271\n",
            "Epoch 4/50 -- Train Loss: 0.4070\n",
            "Epoch 5/50 -- Train Loss: 0.3190\n",
            "Epoch 6/50 -- Train Loss: 0.2857\n",
            "Epoch 7/50 -- Train Loss: 0.2691\n",
            "Epoch 8/50 -- Train Loss: 0.2566\n",
            "Epoch 9/50 -- Train Loss: 0.2470\n",
            "Epoch 10/50 -- Train Loss: 0.2395\n",
            "Epoch 11/50 -- Train Loss: 0.2333\n",
            "Epoch 12/50 -- Train Loss: 0.2301\n",
            "Epoch 13/50 -- Train Loss: 0.2274\n",
            "Epoch 14/50 -- Train Loss: 0.2247\n",
            "Epoch 15/50 -- Train Loss: 0.2229\n",
            "Epoch 16/50 -- Train Loss: 0.2219\n",
            "Epoch 17/50 -- Train Loss: 0.2203\n",
            "Epoch 18/50 -- Train Loss: 0.2190\n",
            "Epoch 19/50 -- Train Loss: 0.2179\n",
            "Epoch 20/50 -- Train Loss: 0.2168\n",
            "Epoch 21/50 -- Train Loss: 0.2166\n",
            "Epoch 22/50 -- Train Loss: 0.2154\n",
            "Epoch 23/50 -- Train Loss: 0.2153\n",
            "Epoch 24/50 -- Train Loss: 0.2141\n",
            "Epoch 25/50 -- Train Loss: 0.2143\n",
            "Epoch 26/50 -- Train Loss: 0.2140\n",
            "Epoch 27/50 -- Train Loss: 0.2126\n",
            "Epoch 28/50 -- Train Loss: 0.2114\n",
            "Epoch 29/50 -- Train Loss: 0.2116\n",
            "Epoch 30/50 -- Train Loss: 0.2106\n",
            "Epoch 31/50 -- Train Loss: 0.2107\n",
            "Epoch 32/50 -- Train Loss: 0.2093\n",
            "Epoch 33/50 -- Train Loss: 0.2098\n",
            "Epoch 34/50 -- Train Loss: 0.2088\n",
            "Epoch 35/50 -- Train Loss: 0.2086\n",
            "Epoch 36/50 -- Train Loss: 0.2079\n",
            "Epoch 37/50 -- Train Loss: 0.2073\n",
            "Epoch 38/50 -- Train Loss: 0.2066\n",
            "Epoch 39/50 -- Train Loss: 0.2056\n",
            "Epoch 40/50 -- Train Loss: 0.2056\n",
            "Epoch 41/50 -- Train Loss: 0.2051\n",
            "Epoch 42/50 -- Train Loss: 0.2044\n",
            "Epoch 43/50 -- Train Loss: 0.2040\n",
            "Epoch 44/50 -- Train Loss: 0.2038\n",
            "Epoch 45/50 -- Train Loss: 0.2032\n",
            "Epoch 46/50 -- Train Loss: 0.2030\n",
            "Epoch 47/50 -- Train Loss: 0.2024\n",
            "Epoch 48/50 -- Train Loss: 0.2023\n",
            "Epoch 49/50 -- Train Loss: 0.2014\n",
            "Epoch 50/50 -- Train Loss: 0.2026\n",
            "Test Loss: 0.2073\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "dataset['STATION'] = dataset['STATION'].astype('category').cat.codes\n",
        "dataset['NAME'] = dataset['NAME'].astype('category').cat.codes\n",
        "\n",
        "features = dataset[['STATION', 'NAME', 'YEAR', 'MONTH', 'DAY']].values\n",
        "targets  = dataset[['TMAX', 'TMIN']].values\n",
        "\n",
        "features_train, features_test, targets_train, targets_test = train_test_split(\n",
        "    features, targets, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "feat_scaler = StandardScaler()\n",
        "target_scaler = StandardScaler()\n",
        "\n",
        "features_train_scaled = feat_scaler.fit_transform(features_train)\n",
        "targets_train_scaled  = target_scaler.fit_transform(targets_train)\n",
        "\n",
        "features_test_scaled = feat_scaler.transform(features_test)\n",
        "targets_test_scaled  = target_scaler.transform(targets_test)\n",
        "\n",
        "def create_sequences(features, targets, seq_len):\n",
        "    X_seq = []\n",
        "    y_seq = []\n",
        "    for i in range(len(features) - seq_len + 1):\n",
        "        X_seq.append(features[i:i+seq_len])\n",
        "        y_seq.append(targets[i+seq_len-1])\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "seq_len = 10\n",
        "\n",
        "X_train_seq, y_train_seq = create_sequences(features_train_scaled, targets_train_scaled, seq_len)\n",
        "X_test_seq, y_test_seq   = create_sequences(features_test_scaled, targets_test_scaled, seq_len)\n",
        "\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train_seq, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train_seq, dtype=torch.float32)\n",
        "X_test_tensor  = torch.tensor(X_test_seq, dtype=torch.float32)\n",
        "y_test_tensor  = torch.tensor(y_test_seq, dtype=torch.float32)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset  = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader  = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader   = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "model = WeatherPredictor(input_size=5, hidden_size=16, output_size=2)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(x_batch)\n",
        "        loss = criterion(predictions, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * x_batch.size(0)\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} -- Train Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "with torch.no_grad():\n",
        "    for x_batch, y_batch in test_loader:\n",
        "        predictions = model(x_batch)\n",
        "        loss = criterion(predictions, y_batch)\n",
        "        test_loss += loss.item() * x_batch.size(0)\n",
        "test_loss /= len(test_dataset)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "788SnIxLHKM2",
        "outputId": "39c11871-380a-4c9b-c245-5c35afe34501"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test MSE Loss: 0.2073\n",
            "Target 0 -- Accuracy: 0.8908, F1 Score: 0.8925\n",
            "Target 1 -- Accuracy: 0.9088, F1 Score: 0.9112\n",
            "Sample Predictions: tensor([[-0.7174, -0.8352],\n",
            "        [ 1.2115,  1.2434],\n",
            "        [-1.2850, -1.3036],\n",
            "        [-1.3602, -1.4438],\n",
            "        [ 0.8224,  0.8507]])\n",
            "Ground Truth: tensor([[-0.1491, -0.2002],\n",
            "        [ 0.9251,  1.4352],\n",
            "        [-1.9583, -2.0779],\n",
            "        [-1.6756, -1.7750],\n",
            "        [ 0.8120,  1.0112]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "y_train = train_dataset.tensors[1]\n",
        "\n",
        "thresholds = torch.median(y_train, dim=0).values\n",
        "\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "all_preds = []\n",
        "all_true = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x_batch, y_batch in test_loader:\n",
        "        predictions = model(x_batch)\n",
        "        loss = criterion(predictions, y_batch)\n",
        "        test_loss += loss.item() * x_batch.size(0)\n",
        "        all_preds.append(predictions)\n",
        "        all_true.append(y_batch)\n",
        "\n",
        "average_test_loss = test_loss / len(test_loader.dataset)\n",
        "print(f\"Test MSE Loss: {average_test_loss:.4f}\")\n",
        "\n",
        "all_preds = torch.cat(all_preds, dim=0)\n",
        "all_true = torch.cat(all_true, dim=0)\n",
        "\n",
        "pred_labels = (all_preds > thresholds).int().cpu().numpy()\n",
        "true_labels = (all_true > thresholds).int().cpu().numpy()\n",
        "\n",
        "accuracies = []\n",
        "f1_scores = []\n",
        "\n",
        "for i in range(2):\n",
        "    acc = accuracy_score(true_labels[:, i], pred_labels[:, i])\n",
        "    f1 = f1_score(true_labels[:, i], pred_labels[:, i])\n",
        "    accuracies.append(acc)\n",
        "    f1_scores.append(f1)\n",
        "    print(f\"Target {i} -- Accuracy: {acc:.4f}, F1 Score: {f1:.4f}\")\n",
        "with torch.no_grad():\n",
        "    for x_batch, y_batch in test_loader:\n",
        "        predictions = model(x_batch)\n",
        "        print(\"Sample Predictions:\", predictions[:5])\n",
        "        print(\"Ground Truth:\", y_batch[:5])\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCjy4K3riKni"
      },
      "source": [
        "Awesome! We found that our reversible cell maintained similar accuracy scores to the standard LSTM. Now to test for actual reversibility..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS4QDhGTfv_P"
      },
      "source": [
        "Initial Reversibility Test of Cell and Hidden States Over a Single Timestep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53TxVhxfiVVt"
      },
      "source": [
        "Here, we're plotting a histogram of cosine similarities between actual previous hidden states and recovered ones, as well as cell states. We also compute the norm of the difference over each tensor, to give us an idea of the order of magnitude error that our approximation was introducing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "id": "9nDmJwNpHfmc",
        "outputId": "08fee9cd-ecc6-4a9e-a1ad-4b1697a74f47"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAHHCAYAAACiOWx7AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAARcVJREFUeJzt3XlcVPX+x/H3AA4gsoiyFim445KlaaiZJkmF3kzLLFPLrRLN5brmnqZmaaa5tFhaYZZl3dK0yK2bct3N3TJxKQUXhHEJUDm/P/oxDydQzyjIqK/n4zGPy3zP95zzOV/Ied9zvueMxTAMQwAAALgst+IuAAAA4EZAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCXMCzzz6r8uXLO7RZLBaNGjWqWOpxVaNGjZLFYinUbV6vsZ8zZ44sFov2799fqNstDAWNAYD8CE3AVfj999/1/PPPKyoqSl5eXvLz81PDhg311ltv6a+//rqutRw7dky9e/dW1apV5e3treDgYNWrV0+DBg3S6dOn7f3mzZunKVOmXPV+zp49q1GjRmnlypXXXvQ/nD59WiNHjlSNGjXk4+OjMmXKqHbt2urdu7cOHz5c6PtzFTNmzNCcOXMKdZv79++XxWLRG2+8UeDyvOB5/Pjxa9rPzp07NWrUKJcMgUBR8SjuAoAbzeLFi/XEE0/I09NTHTt2VI0aNZSTk6Off/5ZAwYM0I4dO/Tuu+9el1rS09NVt25d2Ww2de7cWVWrVtWJEye0detWzZw5Uy+++KJKlSol6e/QtH37dvXp0+eq9nX27FmNHj1aktSkSZNCOgLp3Llzaty4sXbv3q1OnTqpV69eOn36tHbs2KF58+bpscceU3h4uCRp2LBhGjx4cKHtW5Lee+895ebmFuo2C9KhQwe1a9dOnp6e9rYZM2aobNmyevbZZ4t8/5dzNWOwc+dOjR49Wk2aNOEsFW4ZhCbACSkpKWrXrp3KlSun5cuXKywszL4sISFBe/fu1eLFi69bPbNnz9bBgwe1evVqNWjQwGGZzWaT1Wq9brVcra+//lqbN29WYmKinn76aYdlWVlZysnJsb/38PCQh0fh/rNVokSJQt3eP505c0Y+Pj5yd3eXu7t7ke7rahX1GBSFrKwsWa1WublxwQTXD39tgBMmTpyo06dPa/bs2Q6BKU/FihXVu3dvh7ZPPvlEderUkbe3twIDA9WuXTsdOnSoUOr5/fff5e7urnvvvTffMj8/P3l5eUn6+8zQ4sWLdeDAAVksFlksFvvZgZycHI0YMUJ16tSRv7+/fHx8dN9992nFihX2be3fv19BQUGSpNGjR9u3cfG8n927d+vxxx9XYGCgvLy8VLduXX3zzTemjkGSGjZsmG9Z3qXPPAXNabJYLOrZs6cWLFig6OhoeXt7KyYmRtu2bZMkvfPOO6pYsaK8vLzUpEmTfJeTzMznOXDggHr06KEqVarI29tbZcqU0RNPPJFvW3nzllatWqUePXooODhYt99+u8OyvHXKly+vHTt2aNWqVfbxbNKkifbt2yeLxaI333wzXx1r1qyRxWLRp59+etl6nVXQGMyfP1916tSRr6+v/Pz8VLNmTb311lv2Y3niiSckSU2bNrXXf/Gl2xkzZqh69ery9PRUeHi4EhISlJGRkW/f06dPV1RUlLy9vVWvXj3997//VZMmTRzOZq5cuVIWi0Xz58/XsGHDdNttt6lkyZKy2WxKT09X//79VbNmTZUqVUp+fn56+OGH9csvvzjsJ28bn3/+uUaPHq3bbrtNvr6+evzxx5WZmans7Gz16dNHwcHBKlWqlJ577jllZ2cXyvji5sGZJsAJ3377raKiovKd1bmUV199VcOHD1fbtm3VtWtXHTt2TNOmTVPjxo21efNmBQQEXFM95cqV04ULF/Txxx+rU6dOl+w3dOhQZWZm6o8//rB/GOddtrPZbHr//ff11FNPqVu3bjp16pRmz56tuLg4rVu3TrVr11ZQUJD9ct9jjz2m1q1bS5Jq1aolSdqxY4caNmyo2267TYMHD5aPj48+//xztWrVSl9++aUee+yxyx6DJH300UcaNmzYVU30/u9//6tvvvlGCQkJkqTx48erRYsWGjhwoGbMmKEePXro5MmTmjhxojp37qzly5c7tf3169drzZo1ateunW6//Xbt379fM2fOVJMmTbRz506VLFnSoX+PHj0UFBSkESNG6MyZMwVuc8qUKerVq5dKlSqloUOHSpJCQkIUFRWlhg0bKjExUX379nVYJzExUb6+vnr00UevWPPZs2cLnLd09uzZK66blJSkp556Ss2aNdNrr70mSdq1a5dWr16t3r17q3HjxnrppZc0depUvfzyy6pWrZok2f931KhRGj16tGJjY/Xiiy9qz549mjlzptavX6/Vq1fbz2zNnDlTPXv21H333ae+fftq//79atWqlUqXLm0PmxcbM2aMrFar+vfvr+zsbFmtVu3cuVNff/21nnjiCUVGRiotLU3vvPOO7r//fu3cudN+aTfP+PHj5e3trcGDB2vv3r2aNm2aSpQoITc3N508eVKjRo3S//73P82ZM0eRkZEaMWLEFccLtxADgCmZmZmGJOPRRx811X///v2Gu7u78eqrrzq0b9u2zfDw8HBo79Spk1GuXDmHfpKMkSNHXnYfqampRlBQkCHJqFq1qvHCCy8Y8+bNMzIyMvL1jY+Pz7cPwzCM8+fPG9nZ2Q5tJ0+eNEJCQozOnTvb244dO3bJmpo1a2bUrFnTyMrKsrfl5uYaDRo0MCpVqnTZYzh79qxRpUoVQ5JRrlw549lnnzVmz55tpKWl5es7cuRI45//bEkyPD09jZSUFHvbO++8Y0gyQkNDDZvNZm8fMmSIIcmhr5mxP3v2bL5akpOTDUnGRx99ZG/78MMPDUlGo0aNjPPnzzv0z1t28b6rV69u3H///fm2nVf/rl277G05OTlG2bJljU6dOuXrf7GUlBRD0hVfx44du+QY9O7d2/Dz88t3DBdbsGCBIclYsWKFQ/vRo0cNq9VqNG/e3Lhw4YK9/e233zYkGR988IFhGIaRnZ1tlClTxrjnnnuMc+fO2fvNmTPHkOQwLitWrDAkGVFRUfl+F1lZWQ77yRsDT09P45VXXsm3jRo1ahg5OTn29qeeesqwWCzGww8/7LCNmJiYAv97wa2Ny3OASTabTZLk6+trqv/ChQuVm5urtm3b6vjx4/ZXaGioKlWq5HD562qFhITol19+0QsvvKCTJ09q1qxZevrppxUcHKwxY8bIMIwrbsPd3d0+9yk3N1fp6ek6f/686tatq02bNl1x/fT0dC1fvlxt27bVqVOn7Md54sQJxcXF6bffftOff/55yfW9vb21du1aDRgwQNLfl366dOmisLAw9erVy9QlkmbNmjlcXqpfv74kqU2bNg6/r7z2ffv2XXGb/6wxz7lz53TixAlVrFhRAQEBBY5Rt27drmn+Utu2beXl5aXExER72/fff6/jx4/rmWeeMbWN7t27KykpKd+rQ4cOV1w3ICBAZ86cUVJSktO1//jjj8rJyVGfPn0c5ht169ZNfn5+9jl/GzZs0IkTJ9StWzeHeWrt27dX6dKlC9x2p06dHH4XkuTp6Wnfz4ULF3TixAmVKlVKVapUKfB307FjR4c5XPXr15dhGOrcubNDv/r16+vQoUM6f/68kyOAmxmhCTApb27NqVOnTPX/7bffZBiGKlWqpKCgIIfXrl27dPTo0UKpKywsTDNnztSRI0e0Z88eTZ061X5paPbs2aa2MXfuXNWqVUteXl4qU6aMgoKCtHjxYmVmZl5x3b1798owDA0fPjzfcY4cOVKSrnis/v7+mjhxovbv36/9+/dr9uzZqlKlit5++22NGTPmijXccccd+bYnSREREQW2nzx58orbvNhff/2lESNGKCIiQp6enipbtqyCgoKUkZFR4BhFRkY6tf1/CggIUMuWLTVv3jx7W2Jiom677TY98MADprZRqVIlxcbG5ntFRUVdcd0ePXqocuXKevjhh3X77berc+fOWrp0qan9HjhwQJJUpUoVh3ar1aqoqCj78rz/rVixokM/Dw+PS84xK2hcc3Nz9eabb6pSpUoOv5utW7cW+Ltx5m8lNzfX1H8DuHUwpwkwyc/PT+Hh4dq+fbup/rm5ubJYLFqyZEmBZx3y5hQVFovFosqVK6ty5cqKj49XpUqVlJiYqK5du152vU8++UTPPvusWrVqpQEDBig4OFju7u4aP368fZL25eTdqt6/f3/FxcUV2OefH4yXU65cOXXu3FmPPfaYoqKilJiYqLFjx152nUud1blUu5kzcBfr1auXPvzwQ/Xp00cxMTHy9/eXxWJRu3btCrxV/59nQ65Gx44dtWDBAq1Zs0Y1a9bUN998ox49elyXu8WCg4O1ZcsWff/991qyZImWLFmiDz/8UB07dtTcuXOLfP+XUtC4jhs3TsOHD1fnzp01ZswYBQYGys3NTX369Cnwd1PUfyu4uRGaACe0aNFC7777rpKTkxUTE3PZvhUqVJBhGIqMjFTlypWvU4V/i4qKUunSpXXkyBF726UmWH/xxReKiorSwoULHfrknSW60vp5Zy5KlCih2NjYay3drnTp0qpQoYLpkFqUvvjiC3Xq1EmTJk2yt2VlZRV4N5gzLjfp/aGHHlJQUJASExNVv359nT171tSltcJitVrVsmVLtWzZUrm5uerRo4feeecdDR8+XBUrVrxk7XkT+/fs2eNwVisnJ0cpKSn2v5G8fnv37lXTpk3t/c6fP6/9+/fbbzK4ki+++EJNmzbNd1Y1IyNDZcuWNX/AgAlcngOcMHDgQPn4+Khr165KS0vLt/z333+335bdunVrubu7a/To0fn+36phGDpx4sQ117N27doC785at26dTpw44XCJxMfHp8BLDXn/D/viGteuXavk5GSHfnl3iP0zKAQHB6tJkyZ65513HEJanmPHjl32GH755ZcC7/I6cOCAdu7cme8yT3Fwd3fP9zucNm2aLly4cE3b9fHxuWTw8vDw0FNPPaXPP/9cc+bMUc2aNU0HiWv1z79NNzc3+77z5pj5+PhIyv/3EBsbK6vVqqlTpzqM2ezZs5WZman4+HhJUt26dVWmTBm99957DvOGEhMTnbp8WtDvZsGCBZedRwdcLc40AU6oUKGC5s2bpyeffFLVqlVzeCL4mjVrtGDBAvvTnStUqKCxY8dqyJAh9lupfX19lZKSoq+++krdu3dX//79r6mejz/+WImJiXrsscdUp04dWa1W7dq1Sx988IG8vLz08ssv2/vWqVNHn332mfr166d77rlHpUqVUsuWLdWiRQstXLhQjz32mOLj45WSkqJZs2YpOjra4WtYvL29FR0drc8++0yVK1dWYGCgatSooRo1amj69Olq1KiRatasqW7duikqKkppaWlKTk7WH3/8ke+ZORdLSkrSyJEj9a9//Uv33nuvSpUqpX379umDDz5Qdna2S3z/XosWLfTxxx/L399f0dHRSk5O1o8//qgyZcpc03br1KmjmTNnauzYsapYsaKCg4Md5ix17NhRU6dO1YoVK+y3/l8PXbt2VXp6uh544AHdfvvtOnDggKZNm6batWvbHytQu3Ztubu767XXXlNmZqY8PT31wAMPKDg4WEOGDNHo0aP10EMP6V//+pf27NmjGTNm6J577rFPZLdarRo1apR69eqlBx54QG3bttX+/fs1Z84cVahQwfSjJ1q0aKFXXnlFzz33nBo0aKBt27YpMTHR1NwtwGnFcs8ecIP79ddfjW7duhnly5c3rFar4evrazRs2NCYNm2aw233hmEYX375pdGoUSPDx8fH8PHxMapWrWokJCQYe/bssfe52kcObN261RgwYIBx9913G4GBgYaHh4cRFhZmPPHEE8amTZsc+p4+fdp4+umnjYCAAPvt/Ybx96MBxo0bZ5QrV87w9PQ07rrrLmPRokUF1rRmzRqjTp06htVqzVff77//bnTs2NEIDQ01SpQoYdx2221GixYtjC+++OKyx7Bv3z5jxIgRxr333msEBwcbHh4eRlBQkBEfH28sX77coe+lHjmQkJDg0JZ32/3rr7/u0J532/mCBQvsbWbG/uTJk8Zzzz1nlC1b1ihVqpQRFxdn7N692yhXrpzDIwDyHiuwfv36fMdZ0CMHUlNTjfj4eMPX1zffbfZ5qlevbri5uRl//PFHvmUFudSx58kbw8s9cuCLL74wmjdvbgQHBxtWq9W44447jOeff944cuSIw7bee+89IyoqynB3d8/3+IG3337bqFq1qlGiRAkjJCTEePHFF42TJ0/mq2fq1Kn2v7169eoZq1evNurUqWM89NBD9j4F/d7yZGVlGf/+97+NsLAww9vb22jYsKGRnJxs3H///QU+tuCf27jU76ygcQIshsEsNwBwVXfddZcCAwO1bNmy4i7lusjNzVVQUJBat26t9957r7jLARwwpwkAXNSGDRu0ZcsWdezYsbhLKRJZWVn55iN99NFHSk9PL9QvhQYKC2eaAMDFbN++XRs3btSkSZN0/Phx7du3z/49gjeTlStXqm/fvnriiSdUpkwZbdq0SbNnz1a1atW0cePGG+ILp3FrYSI4ALiYL774Qq+88oqqVKmiTz/99KYMTNLfX1ocERGhqVOnKj09XYGBgerYsaMmTJhAYIJL4kwTAACACcxpAgAAMIHQBAAAYAJzmgpJbm6uDh8+LF9fX9MPZQMAAMXLMAydOnVK4eHhV/xuR0JTITl8+HC+b8kGAAA3hkOHDun222+/bB9CUyHx9fWV9Peg+/n5FXM1AADADJvNpoiICPvn+OUQmgpJ3iU5Pz8/QhMAADcYM1NrmAgOAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwIRiDU0//fSTWrZsqfDwcFksFn399dcOyw3D0IgRIxQWFiZvb2/Fxsbqt99+c+iTnp6u9u3by8/PTwEBAerSpYtOnz7t0Gfr1q2677775OXlpYiICE2cODFfLQsWLFDVqlXl5eWlmjVr6rvvviv04wUAADeuYg1NZ86c0Z133qnp06cXuHzixImaOnWqZs2apbVr18rHx0dxcXHKysqy92nfvr127NihpKQkLVq0SD/99JO6d+9uX26z2dS8eXOVK1dOGzdu1Ouvv65Ro0bp3XfftfdZs2aNnnrqKXXp0kWbN29Wq1at1KpVK23fvr3oDh4AANxYDBchyfjqq6/s73Nzc43Q0FDj9ddft7dlZGQYnp6exqeffmoYhmHs3LnTkGSsX7/e3mfJkiWGxWIx/vzzT8MwDGPGjBlG6dKljezsbHufQYMGGVWqVLG/b9u2rREfH+9QT/369Y3nn3/edP2ZmZmGJCMzM9P0OgAAoHg58/ntsnOaUlJSlJqaqtjYWHubv7+/6tevr+TkZElScnKyAgICVLduXXuf2NhYubm5ae3atfY+jRs3ltVqtfeJi4vTnj17dPLkSXufi/eT1ydvPwXJzs6WzWZzeAEAgJuXy4am1NRUSVJISIhDe0hIiH1ZamqqgoODHZZ7eHgoMDDQoU9B27h4H5fqk7e8IOPHj5e/v7/9FRER4ewhAgCAG4hHcRdwoxoyZIj69etnf2+z2QhOAABcQfnBi6963f0T4guxEue57Jmm0NBQSVJaWppDe1pamn1ZaGiojh496rD8/PnzSk9Pd+hT0DYu3sel+uQtL4inp6f8/PwcXgAA4OblsqEpMjJSoaGhWrZsmb3NZrNp7dq1iomJkSTFxMQoIyNDGzdutPdZvny5cnNzVb9+fXufn376SefOnbP3SUpKUpUqVVS6dGl7n4v3k9cnbz8AAADFGppOnz6tLVu2aMuWLZL+nvy9ZcsWHTx4UBaLRX369NHYsWP1zTffaNu2berYsaPCw8PVqlUrSVK1atX00EMPqVu3blq3bp1Wr16tnj17ql27dgoPD5ckPf3007JarerSpYt27Nihzz77TG+99ZbDpbXevXtr6dKlmjRpknbv3q1Ro0Zpw4YN6tmz5/UeEgAA4KKKdU7Thg0b1LRpU/v7vCDTqVMnzZkzRwMHDtSZM2fUvXt3ZWRkqFGjRlq6dKm8vLzs6yQmJqpnz55q1qyZ3Nzc1KZNG02dOtW+3N/fXz/88IMSEhJUp04dlS1bViNGjHB4llODBg00b948DRs2TC+//LIqVaqkr7/+WjVq1LgOowAAAG4EFsMwjOIu4mZgs9nk7++vzMxM5jcBAHAJrjYR3JnPb5ed0wQAAOBKCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmODSoenChQsaPny4IiMj5e3trQoVKmjMmDEyDMPexzAMjRgxQmFhYfL29lZsbKx+++03h+2kp6erffv28vPzU0BAgLp06aLTp0879Nm6davuu+8+eXl5KSIiQhMnTrwuxwgAAG4MLh2aXnvtNc2cOVNvv/22du3apddee00TJ07UtGnT7H0mTpyoqVOnatasWVq7dq18fHwUFxenrKwse5/27dtrx44dSkpK0qJFi/TTTz+pe/fu9uU2m03NmzdXuXLltHHjRr3++usaNWqU3n333et6vAAAwHVZjItP27iYFi1aKCQkRLNnz7a3tWnTRt7e3vrkk09kGIbCw8P173//W/3795ckZWZmKiQkRHPmzFG7du20a9cuRUdHa/369apbt64kaenSpXrkkUf0xx9/KDw8XDNnztTQoUOVmpoqq9UqSRo8eLC+/vpr7d6921StNptN/v7+yszMlJ+fXyGPBAAAN4fygxdf9br7J8QXYiV/c+bz26XPNDVo0EDLli3Tr7/+Kkn65Zdf9PPPP+vhhx+WJKWkpCg1NVWxsbH2dfz9/VW/fn0lJydLkpKTkxUQEGAPTJIUGxsrNzc3rV271t6ncePG9sAkSXFxcdqzZ49OnjxZYG3Z2dmy2WwOLwAAcPPyKO4CLmfw4MGy2WyqWrWq3N3ddeHCBb366qtq3769JCk1NVWSFBIS4rBeSEiIfVlqaqqCg4Mdlnt4eCgwMNChT2RkZL5t5C0rXbp0vtrGjx+v0aNHF8JRAgCAG4FLn2n6/PPPlZiYqHnz5mnTpk2aO3eu3njjDc2dO7e4S9OQIUOUmZlpfx06dKi4SwIAAEXIpc80DRgwQIMHD1a7du0kSTVr1tSBAwc0fvx4derUSaGhoZKktLQ0hYWF2ddLS0tT7dq1JUmhoaE6evSow3bPnz+v9PR0+/qhoaFKS0tz6JP3Pq/PP3l6esrT0/PaDxIAANwQXPpM09mzZ+Xm5liiu7u7cnNzJUmRkZEKDQ3VsmXL7MttNpvWrl2rmJgYSVJMTIwyMjK0ceNGe5/ly5crNzdX9evXt/f56aefdO7cOXufpKQkValSpcBLcwAA4Nbj0qGpZcuWevXVV7V48WLt379fX331lSZPnqzHHntMkmSxWNSnTx+NHTtW33zzjbZt26aOHTsqPDxcrVq1kiRVq1ZNDz30kLp166Z169Zp9erV6tmzp9q1a6fw8HBJ0tNPPy2r1aouXbpox44d+uyzz/TWW2+pX79+xXXoAADAxbj05blp06Zp+PDh6tGjh44eParw8HA9//zzGjFihL3PwIEDdebMGXXv3l0ZGRlq1KiRli5dKi8vL3ufxMRE9ezZU82aNZObm5vatGmjqVOn2pf7+/vrhx9+UEJCgurUqaOyZctqxIgRDs9yAgAAtzaXfk7TjYTnNAEAcGU8pwkAAOAmR2gCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmOB0aNq3b19R1AEAAODSnA5NFStWVNOmTfXJJ58oKyurKGoCAABwOU6Hpk2bNqlWrVrq16+fQkND9fzzz2vdunVFURsAAIDLcDo01a5dW2+99ZYOHz6sDz74QEeOHFGjRo1Uo0YNTZ48WceOHSuKOgEAAIrVVU8E9/DwUOvWrbVgwQK99tpr2rt3r/r376+IiAh17NhRR44cKcw6AQAAitVVh6YNGzaoR48eCgsL0+TJk9W/f3/9/vvvSkpK0uHDh/Xoo48WZp0AAADFysPZFSZPnqwPP/xQe/bs0SOPPKKPPvpIjzzyiNzc/s5fkZGRmjNnjsqXL1/YtQIAABQbp0PTzJkz1blzZz377LMKCwsrsE9wcLBmz559zcUBAAC4CqdDU1JSku644w77maU8hmHo0KFDuuOOO2S1WtWpU6dCKxIAAKC4OT2nqUKFCjp+/Hi+9vT0dEVGRhZKUQAAAK7G6dBkGEaB7adPn5aXl9c1FwQAAOCKTF+e69evnyTJYrFoxIgRKlmypH3ZhQsXtHbtWtWuXbvQCwQAAHAFpkPT5s2bJf19pmnbtm2yWq32ZVarVXfeeaf69+9f+BUCAAC4ANOhacWKFZKk5557Tm+99Zb8/PyKrCgAAABX4/Tdcx9++GFR1AEAAODSTIWm1q1ba86cOfLz81Pr1q0v23fhwoWFUhgAAIArMRWa/P39ZbFY7D8DAADcakyFprxLcoZhaPTo0QoKCpK3t3eRFgYAAOBKnHpOk2EYqlixov7444+iqgcAAMAlORWa3NzcVKlSJZ04caKo6gEAAHBJTj8RfMKECRowYIC2b99eFPUAAAC4JKcfOdCxY0edPXtWd955p6xWa765Tenp6YVWHAAAgKtwOjRNmTKlCMoAAABwbU6Hpk6dOhVFHQAAAC7N6dB0saysLOXk5Di08fUqAADgZuT0RPAzZ86oZ8+eCg4Olo+Pj0qXLu3wAgAAuBk5HZoGDhyo5cuXa+bMmfL09NT777+v0aNHKzw8XB999FGhF/jnn3/qmWeeUZkyZeTt7a2aNWtqw4YN9uWGYWjEiBEKCwuTt7e3YmNj9dtvvzlsIz09Xe3bt5efn58CAgLUpUsXnT592qHP1q1bdd9998nLy0sRERGaOHFioR8LAAC4cTkdmr799lvNmDFDbdq0kYeHh+677z4NGzZM48aNU2JiYqEWd/LkSTVs2FAlSpTQkiVLtHPnTk2aNMnhjNbEiRM1depUzZo1S2vXrpWPj4/i4uKUlZVl79O+fXvt2LFDSUlJWrRokX766Sd1797dvtxms6l58+YqV66cNm7cqNdff12jRo3Su+++W6jHAwAAblxOz2lKT09XVFSUpL/nL+U9YqBRo0Z68cUXC7W41157TREREfavcZGkyMhI+8+GYWjKlCkaNmyYHn30UUnSRx99pJCQEH399ddq166ddu3apaVLl2r9+vWqW7euJGnatGl65JFH9MYbbyg8PFyJiYnKycnRBx98IKvVqurVq2vLli2aPHmyQ7gCAAC3LqfPNEVFRSklJUWSVLVqVX3++eeS/j4DFRAQUKjFffPNN6pbt66eeOIJBQcH66677tJ7771nX56SkqLU1FTFxsba2/z9/VW/fn0lJydLkpKTkxUQEGAPTJIUGxsrNzc3rV271t6ncePGslqt9j5xcXHas2ePTp48WWBt2dnZstlsDi8AAHDzcjo0Pffcc/rll18kSYMHD9b06dPl5eWlvn37asCAAYVa3L59+zRz5kxVqlRJ33//vV588UW99NJLmjt3riQpNTVVkhQSEuKwXkhIiH1ZamqqgoODHZZ7eHgoMDDQoU9B27h4H/80fvx4+fv7218RERHXeLQAAMCVOX15rm/fvvafY2NjtXv3bm3cuFEVK1ZUrVq1CrW43Nxc1a1bV+PGjZMk3XXXXdq+fbtmzZpV7M+LGjJkiPr162d/b7PZCE4AANzEruk5TZJUrlw5lStXrjBqyScsLEzR0dEObdWqVdOXX34pSQoNDZUkpaWlKSwszN4nLS1NtWvXtvc5evSowzbOnz+v9PR0+/qhoaFKS0tz6JP3Pq/PP3l6esrT0/MqjwwAANxoTIWmqVOnmt7gSy+9dNXF/FPDhg21Z88eh7Zff/3VHtIiIyMVGhqqZcuW2UOSzWbT2rVr7ZPSY2JilJGRoY0bN6pOnTqSpOXLlys3N1f169e39xk6dKjOnTunEiVKSJKSkpJUpUoVnj0FAAAkSRbDMIwrdbr4jrXLbsxi0b59+665qDzr169XgwYNNHr0aLVt21br1q1Tt27d9O6776p9+/aS/r7DbsKECZo7d64iIyM1fPhwbd26VTt37pSXl5ck6eGHH1ZaWppmzZqlc+fO6bnnnlPdunU1b948SVJmZqaqVKmi5s2ba9CgQdq+fbs6d+6sN9980/TdczabTf7+/srMzOSp6AAAXEL5wYuvet39E+ILsZK/OfP5bepMU97dctfbPffco6+++kpDhgzRK6+8osjISE2ZMsUemKS/H7Z55swZde/eXRkZGWrUqJGWLl1qD0ySlJiYqJ49e6pZs2Zyc3NTmzZtHM6e+fv764cfflBCQoLq1KmjsmXLasSIETxuAAAA2Jk604Qr40wTAABXdtOfaerXr5/GjBkjHx8fhzvGCjJ58mTzlQIAANwgTIWmzZs369y5c/afL8VisRROVQAAAC7GVGhasWJFgT8DAADcKpx+IjgAAMCtyOmHW2ZlZWnatGlasWKFjh49qtzcXIflmzZtKrTiAAAAXIXToalLly764Ycf9Pjjj6tevXrMYwIAALcEp0PTokWL9N1336lhw4ZFUQ8AAIBLcnpO02233SZfX9+iqAUAAMBlOR2aJk2apEGDBunAgQNFUQ8AAIBLcvryXN26dZWVlaWoqCiVLFnS/gW3edLT0wutOAAAAFfhdGh66qmn9Oeff2rcuHEKCQlhIjgAALglOB2a1qxZo+TkZN15551FUQ8AAIBLcnpOU9WqVfXXX38VRS0AAAAuy+nQNGHCBP373//WypUrdeLECdlsNocXAADAzcjpy3MPPfSQJKlZs2YO7YZhyGKx6MKFC4VTGQAAgAtxOjTxhb0AAOBW5HRouv/++4uiDgAAAJdmKjRt3bpVNWrUkJubm7Zu3XrZvrVq1SqUwgAAAFyJqdBUu3ZtpaamKjg4WLVr15bFYpFhGPn6MacJAADcrEyFppSUFAUFBdl/BgAAuNWYCk3lypUr8GcAAIBbhennNP36669at26dQ9uyZcvUtGlT1atXT+PGjSv04gAAAFyF6dA0aNAgLVq0yP4+JSVFLVu2lNVqVUxMjMaPH68pU6YURY0AAADFzvQjBzZs2KCBAwfa3ycmJqpy5cr6/vvvJf1919y0adPUp0+fQi8SAACguJk+03T8+HHdfvvt9vcrVqxQy5Yt7e+bNGmi/fv3F2pxAAAArsJ0aAoMDNSRI0ckSbm5udqwYYPuvfde+/KcnJwCH0MAAABwMzAdmpo0aaIxY8bo0KFDmjJlinJzc9WkSRP78p07d6p8+fJFUCIAAEDxMz2n6dVXX9WDDz6ocuXKyd3dXVOnTpWPj499+ccff6wHHnigSIoEAAAobqZDU/ny5bVr1y7t2LFDQUFBCg8Pd1g+evRohzlPAAAANxOnvrDXw8NDd955Z4HLLtUOAABwMzA9pwkAAOBWRmgCAAAwgdAEAABgAqEJAADAhKsKTf/973/1zDPPKCYmRn/++aekvx858PPPPxdqcQAAAK7C6dD05ZdfKi4uTt7e3tq8ebOys7MlSZmZmRo3blyhFwgAAOAKnA5NY8eO1axZs/Tee++pRIkS9vaGDRtq06ZNhVocAACAq3A6NO3Zs0eNGzfO1+7v76+MjIzCqAkAAMDlOB2aQkNDtXfv3nztP//8s6KiogqlKAAAAFfjdGjq1q2bevfurbVr18pisejw4cNKTExU//799eKLLxZFjQAAAMXOqa9RkaTBgwcrNzdXzZo109mzZ9W4cWN5enqqf//+6tWrV1HUCAAAUOycDk0Wi0VDhw7VgAEDtHfvXp0+fVrR0dEqVapUUdQHAADgEpwOTXmsVquio6MLsxYAAACX5XRoOnPmjCZMmKBly5bp6NGjys3NdVi+b9++QisOAADAVTgdmrp27apVq1apQ4cOCgsLk8ViKYq6AAAAXIrToWnJkiVavHixGjZsWBT1AAAAuCSnHzlQunRpBQYGFkUtAAAALsvp0DRmzBiNGDFCZ8+eLYp6AAAAXJLTl+cmTZqk33//XSEhISpfvrzD989J4vvnAADATcnp0NSqVasiKAMAAMC1OR2aRo4cWRR1AAAAuDSn5zQBAADcikydaQoMDNSvv/6qsmXLqnTp0pd9NlN6enqhFQcAAOAqTIWmN998U76+vvafeaAlAAC41ZgKTZ06dbL//OyzzxZVLQAAAC7L6TlNmzZt0rZt2+zv//Of/6hVq1Z6+eWXlZOTU6jFAQAAuAqnQ9Pzzz+vX3/9VdLfX8775JNPqmTJklqwYIEGDhxY6AUCAAC4AqdD06+//qratWtLkhYsWKD7779f8+bN05w5c/Tll18Wdn0AAAAuwenQZBiGcnNzJUk//vijHnnkEUlSRESEjh8/XrjVAQAAuAinQ1PdunU1duxYffzxx1q1apXi4+MlSSkpKQoJCSn0Ai82YcIEWSwW9enTx96WlZWlhIQElSlTRqVKlVKbNm2UlpbmsN7BgwcVHx+vkiVLKjg4WAMGDND58+cd+qxcuVJ33323PD09VbFiRc2ZM6dIjwUAANxYnA5NU6ZM0aZNm9SzZ08NHTpUFStWlCR98cUXatCgQaEXmGf9+vV65513VKtWLYf2vn376ttvv9WCBQu0atUqHT58WK1bt7Yvv3DhguLj45WTk6M1a9Zo7ty5mjNnjkaMGGHvk5KSovj4eDVt2lRbtmxRnz591LVrV33//fdFdjwAAODGYjEMwyiMDWVlZcnd3T3fF/gWhtOnT+vuu+/WjBkzNHbsWNWuXVtTpkxRZmamgoKCNG/ePD3++OOSpN27d6tatWpKTk7WvffeqyVLlqhFixY6fPiw/UzYrFmzNGjQIB07dkxWq1WDBg3S4sWLtX37dvs+27Vrp4yMDC1dutRUjTabTf7+/srMzJSfn1+hjwEAADeD8oMXX/W6+yfEF2Ilf3Pm8/uqv0Zl48aN+uSTT/TJJ59o06ZN8vLyKpLAJEkJCQmKj49XbGxsvhrOnTvn0F61alXdcccdSk5OliQlJyerZs2aDpcO4+LiZLPZtGPHDnuff247Li7Ovg0AAACnv7D36NGjevLJJ7Vq1SoFBARIkjIyMtS0aVPNnz9fQUFBhVrg/PnztWnTJq1fvz7fstTUVFmtVnsdeUJCQpSammrv88+5Vnnvr9THZrPpr7/+kre3d759Z2dnKzs72/7eZrM5f3AAAOCG4fSZpl69eun06dPasWOH0tPTlZ6eru3bt8tms+mll14q1OIOHTqk3r17KzExUV5eXoW67Ws1fvx4+fv7218RERHFXRIAAChCToempUuXasaMGapWrZq9LTo6WtOnT9eSJUsKtbiNGzfq6NGjuvvuu+Xh4SEPDw+tWrVKU6dOlYeHh0JCQpSTk6OMjAyH9dLS0hQaGipJCg0NzXc3Xd77K/Xx8/Mr8CyTJA0ZMkSZmZn216FDhwrjkAEAgItyOjTl5uYWOHepRIkS9uc3FZZmzZpp27Zt2rJli/1Vt25dtW/f3v5ziRIltGzZMvs6e/bs0cGDBxUTEyNJiomJ0bZt23T06FF7n6SkJPn5+Sk6Otre5+Jt5PXJ20ZBPD095efn5/ACAAA3L6fnND3wwAPq3bu3Pv30U4WHh0uS/vzzT/Xt21fNmjUr1OJ8fX1Vo0YNhzYfHx+VKVPG3t6lSxf169dPgYGB8vPzU69evRQTE6N7771XktS8eXNFR0erQ4cOmjhxolJTUzVs2DAlJCTI09NTkvTCCy/o7bff1sCBA9W5c2ctX75cn3/+uRYvvvoZ/gAA4Obi9Jmmt99+WzabTeXLl1eFChVUoUIFRUZGymazadq0aUVR42W9+eabatGihdq0aaPGjRsrNDRUCxcutC93d3fXokWL5O7urpiYGD3zzDPq2LGjXnnlFXufyMhILV68WElJSbrzzjs1adIkvf/++4qLi7vuxwMAAFzTVT2nyTAM/fjjj9q9e7ckqVq1avlu2b/V8JwmAACu7EZ+TpPTl+ckyWKx6MEHH9SDDz54VQUCAADcaExfnlu+fLmio6MLfB5RZmamqlevrv/+97+FWhwAAICrMB2apkyZom7duhV46srf31/PP/+8Jk+eXKjFAQAAuArToemXX37RQw89dMnlzZs318aNGwulKAAAAFdjOjSlpaVd9rvlPDw8dOzYsUIpCgAAwNWYDk233Xabtm/ffsnlW7duVVhYWKEUBQAA4GpMh6ZHHnlEw4cPV1ZWVr5lf/31l0aOHKkWLVoUanEAAACuwvQjB4YNG6aFCxeqcuXK6tmzp6pUqSJJ2r17t6ZPn64LFy5o6NChRVYoAABAcTIdmkJCQrRmzRq9+OKLGjJkiPKeiWmxWBQXF6fp06crJCSkyAoFAAAoTk493LJcuXL67rvvdPLkSe3du1eGYahSpUoqXbp0UdUHAADgEq7qieClS5fWPffcU9i1AAAAuCynv7AXAADgVkRoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmODSoWn8+PG655575Ovrq+DgYLVq1Up79uxx6JOVlaWEhASVKVNGpUqVUps2bZSWlubQ5+DBg4qPj1fJkiUVHBysAQMG6Pz58w59Vq5cqbvvvluenp6qWLGi5syZU9SHBwAAbiAuHZpWrVqlhIQE/e9//1NSUpLOnTun5s2b68yZM/Y+ffv21bfffqsFCxZo1apVOnz4sFq3bm1ffuHCBcXHxysnJ0dr1qzR3LlzNWfOHI0YMcLeJyUlRfHx8WratKm2bNmiPn36qGvXrvr++++v6/ECAADXZTEMwyjuIsw6duyYgoODtWrVKjVu3FiZmZkKCgrSvHnz9Pjjj0uSdu/erWrVqik5OVn33nuvlixZohYtWujw4cMKCQmRJM2aNUuDBg3SsWPHZLVaNWjQIC1evFjbt2+376tdu3bKyMjQ0qVLTdVms9nk7++vzMxM+fn5Ff7BAwBwEyg/ePFVr7t/QnwhVvI3Zz6/XfpM0z9lZmZKkgIDAyVJGzdu1Llz5xQbG2vvU7VqVd1xxx1KTk6WJCUnJ6tmzZr2wCRJcXFxstls2rFjh73PxdvI65O3jYJkZ2fLZrM5vAAAwM3rhglNubm56tOnjxo2bKgaNWpIklJTU2W1WhUQEODQNyQkRKmpqfY+FwemvOV5yy7Xx2az6a+//iqwnvHjx8vf39/+ioiIuOZjBAAAruuGCU0JCQnavn275s+fX9ylSJKGDBmizMxM++vQoUPFXRIAAChCHsVdgBk9e/bUokWL9NNPP+n222+3t4eGhionJ0cZGRkOZ5vS0tIUGhpq77Nu3TqH7eXdXXdxn3/ecZeWliY/Pz95e3sXWJOnp6c8PT2v+dgAAMCNwaXPNBmGoZ49e+qrr77S8uXLFRkZ6bC8Tp06KlGihJYtW2Zv27Nnjw4ePKiYmBhJUkxMjLZt26ajR4/a+yQlJcnPz0/R0dH2PhdvI69P3jYAAABc+kxTQkKC5s2bp//85z/y9fW1z0Hy9/eXt7e3/P391aVLF/Xr10+BgYHy8/NTr169FBMTo3vvvVeS1Lx5c0VHR6tDhw6aOHGiUlNTNWzYMCUkJNjPFL3wwgt6++23NXDgQHXu3FnLly/X559/rsWLr36GPwAAuLm49JmmmTNnKjMzU02aNFFYWJj99dlnn9n7vPnmm2rRooXatGmjxo0bKzQ0VAsXLrQvd3d316JFi+Tu7q6YmBg988wz6tixo1555RV7n8jISC1evFhJSUm68847NWnSJL3//vuKi4u7rscLAABc1w31nCZXxnOaAAC4Mp7TBAAAcJMjNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdD0D9OnT1f58uXl5eWl+vXra926dcVdEgAAcAGEpot89tln6tevn0aOHKlNmzbpzjvvVFxcnI4ePVrcpQEAgGJGaLrI5MmT1a1bNz333HOKjo7WrFmzVLJkSX3wwQfFXRoAAChmhKb/l5OTo40bNyo2Ntbe5ubmptjYWCUnJxdjZQAAwBV4FHcBruL48eO6cOGCQkJCHNpDQkK0e/fufP2zs7OVnZ1tf5+ZmSlJstlsRVsoAAA3sNzss1e9blF8xuZt0zCMK/YlNF2l8ePHa/To0fnaIyIiiqEaAABufv5Tim7bp06dkr+//2X7EJr+X9myZeXu7q60tDSH9rS0NIWGhubrP2TIEPXr18/+Pjc3V+np6SpTpowsFkuR13ujs9lsioiI0KFDh+Tn51fc5dxQGLtrw/hdPcbu2jB+16aoxs8wDJ06dUrh4eFX7Eto+n9Wq1V16tTRsmXL1KpVK0l/B6Fly5apZ8+e+fp7enrK09PToS0gIOA6VHpz8fPz4x+Pq8TYXRvG7+oxdteG8bs2RTF+VzrDlIfQdJF+/fqpU6dOqlu3rurVq6cpU6bozJkzeu6554q7NAAAUMwITRd58skndezYMY0YMUKpqamqXbu2li5dmm9yOAAAuPUQmv6hZ8+eBV6OQ+Hy9PTUyJEj813ixJUxdteG8bt6jN21YfyujSuMn8Uwc48dAADALY6HWwIAAJhAaAIAADCB0AQAAGACoQkAAMAEQhOKzPTp01W+fHl5eXmpfv36Wrdu3WX7L1iwQFWrVpWXl5dq1qyp77777jpV6nqcGbv33ntP9913n0qXLq3SpUsrNjb2imN9s3P2by/P/PnzZbFY7A+4vRU5O3YZGRlKSEhQWFiYPD09VblyZf7bdWL8pkyZoipVqsjb21sRERHq27evsrKyrlO1ruOnn35Sy5YtFR4eLovFoq+//vqK66xcuVJ33323PD09VbFiRc2ZM6fI65QBFIH58+cbVqvV+OCDD4wdO3YY3bp1MwICAoy0tLQC+69evdpwd3c3Jk6caOzcudMYNmyYUaJECWPbtm3XufLi5+zYPf3008b06dONzZs3G7t27TKeffZZw9/f3/jjjz+uc+Wuwdnxy5OSkmLcdtttxn333Wc8+uij16dYF+Ps2GVnZxt169Y1HnnkEePnn382UlJSjJUrVxpbtmy5zpW7BmfHLzEx0fD09DQSExONlJQU4/vvvzfCwsKMvn37XufKi993331nDB061Fi4cKEhyfjqq68u23/fvn1GyZIljX79+hk7d+40pk2bZri7uxtLly4t0joJTSgS9erVMxISEuzvL1y4YISHhxvjx48vsH/btm2N+Ph4h7b69esbzz//fJHW6YqcHbt/On/+vOHr62vMnTu3qEp0aVczfufPnzcaNGhgvP/++0anTp1u2dDk7NjNnDnTiIqKMnJycq5XiS7N2fFLSEgwHnjgAYe2fv36GQ0bNizSOl2dmdA0cOBAo3r16g5tTz75pBEXF1eElRkGl+dQ6HJycrRx40bFxsba29zc3BQbG6vk5OQC10lOTnboL0lxcXGX7H+zupqx+6ezZ8/q3LlzCgwMLKoyXdbVjt8rr7yi4OBgdenS5XqU6ZKuZuy++eYbxcTEKCEhQSEhIapRo4bGjRunCxcuXK+yXcbVjF+DBg20ceNG+yW8ffv26bvvvtMjjzxyXWq+kRXXZwZPBEehO378uC5cuJDv62dCQkK0e/fuAtdJTU0tsH9qamqR1emKrmbs/mnQoEEKDw/P9w/KreBqxu/nn3/W7NmztWXLlutQoeu6mrHbt2+fli9frvbt2+u7777T3r171aNHD507d04jR468HmW7jKsZv6efflrHjx9Xo0aNZBiGzp8/rxdeeEEvv/zy9Sj5hnapzwybzaa//vpL3t7eRbJfzjQBN5EJEyZo/vz5+uqrr+Tl5VXc5bi8U6dOqUOHDnrvvfdUtmzZ4i7nhpObm6vg4GC9++67qlOnjp588kkNHTpUs2bNKu7SbggrV67UuHHjNGPGDG3atEkLFy7U4sWLNWbMmOIuDZfAmSYUurJly8rd3V1paWkO7WlpaQoNDS1wndDQUKf636yuZuzyvPHGG5owYYJ+/PFH1apVqyjLdFnOjt/vv/+u/fv3q2XLlva23NxcSZKHh4f27NmjChUqFG3RLuJq/vbCwsJUokQJubu729uqVaum1NRU5eTkyGq1FmnNruRqxm/48OHq0KGDunbtKkmqWbOmzpw5o+7du2vo0KFyc+O8xqVc6jPDz8+vyM4ySZxpQhGwWq2qU6eOli1bZm/Lzc3VsmXLFBMTU+A6MTExDv0lKSkp6ZL9b1ZXM3aSNHHiRI0ZM0ZLly5V3bp1r0epLsnZ8atataq2bdumLVu22F//+te/1LRpU23ZskURERHXs/xidTV/ew0bNtTevXvtQVOSfv31V4WFhd1SgUm6uvE7e/ZsvmCUF0ANvhb2sortM6NIp5njljV//nzD09PTmDNnjrFz506je/fuRkBAgJGammoYhmF06NDBGDx4sL3/6tWrDQ8PD+ONN94wdu3aZYwcOfKWfuSAM2M3YcIEw2q1Gl988YVx5MgR++vUqVPFdQjFytnx+6db+e45Z8fu4MGDhq+vr9GzZ09jz549xqJFi4zg4GBj7NixxXUIxcrZ8Rs5cqTh6+trfPrpp8a+ffuMH374wahQoYLRtm3b4jqEYnPq1Clj8+bNxubNmw1JxuTJk43NmzcbBw4cMAzDMAYPHmx06NDB3j/vkQMDBgwwdu3aZUyfPp1HDuDGNm3aNOOOO+4wrFarUa9ePeN///uffdn9999vdOrUyaH/559/blSuXNmwWq1G9erVjcWLF1/nil2HM2NXrlw5Q1K+18iRI69/4S7C2b+9i93KockwnB+7NWvWGPXr1zc8PT2NqKgo49VXXzXOnz9/nat2Hc6M37lz54xRo0YZFSpUMLy8vIyIiAijR48exsmTJ69/4cVsxYoVBf47ljdenTp1Mu6///5869SuXduwWq1GVFSU8eGHHxZ5nRbD4BwgAADAlTCnCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQnATSc1NVW9evVSVFSUPD09FRERoZYtW+b7rqqiZrFY9PXXX1/XfQIoOh7FXQAAFKb9+/erYcOGCggI0Ouvv66aNWvq3Llz+v7775WQkKDdu3cXd4kAblCcaQJwU+nRo4csFovWrVunNm3aqHLlyqpevbr69eun//3vf5KkgwcP6tFHH1WpUqXk5+entm3bKi0tzb6NZ599Vq1atXLYbp8+fdSkSRP7+yZNmuill17SwIEDFRgYqNDQUI0aNcq+vHz58pKkxx57TBaLxf7+l19+UdOmTeXr6ys/Pz/VqVNHGzZsKIqhAFDICE0Abhrp6elaunSpEhIS5OPjk295QECAcnNz9eijjyo9PV2rVq1SUlKS9u3bpyeffNLp/c2dO1c+Pj5au3atJk6cqFdeeUVJSUmSpPXr10uSPvzwQx05csT+vn379rr99tu1fv16bdy4UYMHD1aJEiWu4agBXC9cngNw09i7d68Mw1DVqlUv2WfZsmXatm2bUlJSFBERIUn66KOPVL16da1fv1733HOP6f3VqlVLI0eOlCRVqlRJb7/9tpYtW6YHH3xQQUFBkv4OaqGhofZ1Dh48qAEDBthrrFSpktPHCaB4cKYJwE3DMIwr9tm1a5ciIiLsgUmSoqOjFRAQoF27djm1v1q1ajm8DwsL09GjRy+7Tr9+/dS1a1fFxsZqwoQJ+v33353aJ4DiQ2gCcNOoVKmSLBbLNU/2dnNzyxfAzp07l6/fPy+rWSwW5ebmXnbbo0aN0o4dOxQfH6/ly5crOjpaX3311TXVC+D6IDQBuGkEBgYqLi5O06dP15kzZ/Itz8jIULVq1XTo0CEdOnTI3r5z505lZGQoOjpakhQUFKQjR444rLtlyxan6ylRooQuXLiQr71y5crq27evfvjhB7Vu3Voffvih09sGcP0RmgDcVKZPn64LFy6oXr16+vLLL/Xbb79p165dmjp1qmJiYhQbG6uaNWuqffv22rRpk9atW6eOHTvq/vvvV926dSVJDzzwgDZs2KCPPvpIv/32m0aOHKnt27c7XUv58uW1bNkypaam6uTJk/rrr7/Us2dPrVy5UgcOHNDq1au1fv16VatWrbCHAUARIDQBuKlERUVp06ZNatq0qf7973+rRo0aevDBB7Vs2TLNnDlTFotF//nPf1S6dGk1btxYsbGxioqK0meffWbfRlxcnIYPH66BAwfqnnvu0alTp9SxY0ena5k0aZKSkpIUERGhu+66S+7u7jpx4oQ6duyoypUrq23btnr44Yc1evTowhwCAEXEYpiZOQkAAHCL40wTAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEz4P4nC0p/HGsgJAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.87% of the time... it works 100% of the time...\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "sims = []\n",
        "sims_cell = []\n",
        "\n",
        "count = 0\n",
        "for i in range(10000):\n",
        "  input_size = 5\n",
        "  hidden_size = 16\n",
        "  batch_size = 4\n",
        "  timesteps = 5\n",
        "\n",
        "  rev_cell = ReversibleLSTMCell(input_size, hidden_size)\n",
        "\n",
        "  x_seq = torch.randn(timesteps, batch_size, input_size)\n",
        "  h0 = torch.randn(batch_size, hidden_size)\n",
        "  c0 = torch.randn(batch_size, hidden_size)\n",
        "\n",
        "\n",
        "  #need to do multiple forward passes bc h0 is not computed by the network and thus not recoverable\n",
        "  forward_states = [(h0, c0)]\n",
        "  h, c = h0, c0\n",
        "  for t in range(timesteps):\n",
        "      h, c = rev_cell(x_seq[t], h, c)\n",
        "      forward_states.append((h, c))\n",
        "\n",
        "\n",
        "  h_last, c_last = forward_states[-1]\n",
        "  x_last = x_seq[timesteps-1]\n",
        "\n",
        "  recovered_h, recovered_c = rev_cell.reverse(x_last, h_last, c_last)\n",
        "\n",
        "  orig_h, orig_c = forward_states[-2]\n",
        "\n",
        "  h_diff = torch.norm(orig_h - recovered_h)\n",
        "  c_diff = torch.norm(orig_c - recovered_c)\n",
        "  cos_sim_h = F.cosine_similarity(orig_h.flatten().unsqueeze(0), recovered_h.flatten().unsqueeze(0))\n",
        "  cos_sim_c = F.cosine_similarity(orig_c.flatten().unsqueeze(0), recovered_c.flatten().unsqueeze(0))\n",
        "  sims.append(cos_sim_h.item())\n",
        "  sims_cell.append(cos_sim_c.item())\n",
        "  if cos_sim_h.item() > 0.8:\n",
        "    count += 1\n",
        "  # print(orig_h.tolist())\n",
        "  # print(recovered_h.tolist())\n",
        "  # print(f\"Difference in hidden state: {h_diff.item():.6f}\")\n",
        "  # print(f\"Difference in cell state: {c_diff.item():.6f}\")\n",
        "  # print(f\"Cosine similarity of hidden: {cos_sim_h.item()}\")\n",
        "  # print(f\"Cosine similarity of cell: {cos_sim_c.item()}\")\n",
        "\n",
        "plt.hist(np.array(sims), density=False, bins=30)\n",
        "plt.xlabel('Counts')\n",
        "plt.ylabel('Cosine Similarity')\n",
        "plt.title('Hidden State Similarity Histogram')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(np.array(sims_cell), density=False, bins=30)\n",
        "plt.xlabel('Counts')\n",
        "plt.ylabel('Cosine Similarity')\n",
        "plt.title('Cell State Similarity Histogram')\n",
        "plt.show()\n",
        "print(f\"{count/10000 * 100}% of the time... it works 100% of the time...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QgO_zQQip6H"
      },
      "source": [
        "In attempting to improve reversibility, we narrowed it down to an issue with the line where we compute the hidden state, since the cell state seemed to be recovered just fine. This left us with two options for potential issues: the leaky ReLu activation on cell state, and the output gate recoverability. Removing the leaky ReLu activation on the cell state and making it linear instead (ie, h = o * c) didn't seem to do anything, so we tried to see if our output gates were being effectively recovered."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjyyn2w1gQfy",
        "outputId": "19eb6666-4aef-4c0a-b0ea-c7c1e4b4b900"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity for output gate o1: 0.9996269941329956\n",
            "Cosine similarity for output gate o2: 0.9992310404777527\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "input_size = 5\n",
        "hidden_size = 16\n",
        "batch_size = 4\n",
        "half = hidden_size // 2\n",
        "rev_cell = ReversibleLSTMCell(input_size, hidden_size)\n",
        "\n",
        "#burn/random init\n",
        "x = torch.randn(batch_size, input_size)\n",
        "h_base = torch.randn(batch_size, hidden_size)\n",
        "c_base = torch.randn(batch_size, hidden_size)\n",
        "new_h, new_c = rev_cell(x, h_base, c_base)\n",
        "\n",
        "#actual\n",
        "x0 = torch.randn(batch_size, input_size)\n",
        "h0 = new_h\n",
        "c0 = new_c\n",
        "new_h, new_c = rev_cell(x, h0, c0)\n",
        "\n",
        "recovered_h, recovered_c = rev_cell.reverse(x, new_h, new_c)\n",
        "\n",
        "h2_fwd = new_h[:, half:]\n",
        "combined1_fwd = torch.cat([x, h2_fwd], dim=1)\n",
        "o1_fwd = F.leaky_relu(rev_cell.o1(combined1_fwd))\n",
        "\n",
        "h1_fwd = new_h[:, :half]\n",
        "combined2_fwd = torch.cat([x, h1_fwd], dim=1)\n",
        "o2_fwd = F.leaky_relu(rev_cell.o2(combined2_fwd))\n",
        "\n",
        "h2_rev = recovered_h[:, half:]\n",
        "combined1_rev = torch.cat([x, h2_rev], dim=1)\n",
        "o1_rev = F.leaky_relu(rev_cell.o1(combined1_rev))\n",
        "\n",
        "h1_rev = recovered_h[:, :half]\n",
        "combined2_rev = torch.cat([x, h1_rev], dim=1)\n",
        "o2_rev = F.leaky_relu(rev_cell.o2(combined2_rev))\n",
        "\n",
        "cos_sim_o1 = F.cosine_similarity(o1_fwd.flatten().unsqueeze(0), o1_rev.flatten().unsqueeze(0))\n",
        "cos_sim_o2 = F.cosine_similarity(o2_fwd.flatten().unsqueeze(0), o2_rev.flatten().unsqueeze(0))\n",
        "\n",
        "print(\"Cosine similarity for output gate o1:\", cos_sim_o1.item())\n",
        "print(\"Cosine similarity for output gate o2:\", cos_sim_o2.item())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUIAYGP9j1it"
      },
      "source": [
        "As you can see from the above, the output gates were recovered effectively. This left the only source of error as the actual multiplication operation between the activated cell state and the output gate. For the sake of ablation testing, we tried replacing this with an additive operation (ie, h = o + c), and this did indeed improve reversibility, generating < 0.9 cosine similarity scores between actual and recovered hidden states about 90% of the time. However, this gets away from the inherent dynamics of an LSTM, in that the purpose of the Hadamard product operation is to act as an actual gate, causing large effects on the hidden state from the cell state. Adding the two negates the purpose of this, as it only modifies the hidden state by a comparitively small amount wrt the cell state. Thus, we decided to keep the architecture as is, maintaining the characteristics of an LSTM but with only very roughly approximate reversibility."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOFTweI_H-du"
      },
      "source": [
        "Max Sequence Length Reversibility Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYlSHKxjlG8C"
      },
      "source": [
        "Now, we wanted to see how many timesteps we could reverse over."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZfmsLkGH7Os",
        "outputId": "044f2f62-6699-48cf-e198-9536dcdd220a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing approximate reversibility over different sequence lengths:\n",
            "Sequence Length:  1  -  Hidden Diff: 1.200497, Cell Diff: 0.158134\n",
            "Cosine similarities for length  1: Hidden: tensor([0.3423, 0.9188, 0.9455, 0.9728]), Cell: tensor([0.9995, 0.9999, 1.0000, 1.0000])\n",
            "Sequence Length:  2  -  Hidden Diff: 1.510800, Cell Diff: 0.678211\n",
            "Cosine similarities for length  2: Hidden: tensor([0.7313, 0.7748, 0.7284, 0.5034]), Cell: tensor([0.9832, 0.9998, 0.9998, 0.9988])\n",
            "Sequence Length:  5  -  Hidden Diff: 0.709078, Cell Diff: 0.340351\n",
            "Cosine similarities for length  5: Hidden: tensor([ 0.1931,  0.8171, -0.3100,  0.7483]), Cell: tensor([0.9999, 0.9985, 0.9947, 0.9997])\n",
            "Sequence Length: 10  -  Hidden Diff: 1.423560, Cell Diff: 2.077844\n",
            "Cosine similarities for length 10: Hidden: tensor([ 0.9263,  0.5548,  0.7855, -0.0170]), Cell: tensor([0.9976, 0.9683, 0.9171, 0.9492])\n",
            "Sequence Length: 20  -  Hidden Diff: 9.677454, Cell Diff: 57.163315\n",
            "Cosine similarities for length 20: Hidden: tensor([ 0.2348,  0.0262,  0.4866, -0.0808]), Cell: tensor([0.7368, 0.3658, 0.5444, 0.2530])\n",
            "Sequence Length: 50  -  Hidden Diff: nan, Cell Diff: nan\n",
            "Cosine similarities for length 50: Hidden: tensor([nan, nan, nan, nan]), Cell: tensor([nan, nan, nan, nan])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-161-fed916532d91>:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  h_sim = F.cosine_similarity(torch.tensor(forward_states[0][0]), torch.tensor(recovered_states[0][0]))\n",
            "<ipython-input-161-fed916532d91>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  c_sim = F.cosine_similarity(torch.tensor(forward_states[0][1]), torch.tensor(recovered_states[0][1]))\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def test_reversibility_for_seq_length(seq_len, input_size, hidden_size, batch_size=4, burn_in_steps=1):\n",
        "    rev_cell = ReversibleLSTMCell(input_size, hidden_size)\n",
        "    h0 = torch.randn(batch_size, hidden_size)\n",
        "    c0 = torch.randn(batch_size, hidden_size)\n",
        "\n",
        "    #need to \"burn\" a forward pass so what we're attempting to recover was something actually generated by the network and not just a bunch of random numbers\n",
        "    x_burn = torch.randn(batch_size, input_size)\n",
        "    h_burn, c_burn = rev_cell(x_burn, h0, c0)\n",
        "\n",
        "    x_seq = torch.randn(seq_len, batch_size, input_size)\n",
        "\n",
        "    forward_states = [(h_burn, c_burn)]\n",
        "    h, c = h_burn, c_burn\n",
        "    for t in range(seq_len):\n",
        "        h, c = rev_cell(x_seq[t], h, c)\n",
        "        forward_states.append((h, c))\n",
        "\n",
        "    recovered_states = [None] * (seq_len + 1)\n",
        "    recovered_states[seq_len] = forward_states[seq_len]\n",
        "    for t in range(seq_len, 0, -1):\n",
        "        h_rec, c_rec = rev_cell.reverse(x_seq[t-1], recovered_states[t][0], recovered_states[t][1])\n",
        "        recovered_states[t-1] = (h_rec, c_rec)\n",
        "\n",
        "    h_diff = torch.norm(forward_states[0][0] - recovered_states[0][0])\n",
        "    c_diff = torch.norm(forward_states[0][1] - recovered_states[0][1])\n",
        "    h_sim = F.cosine_similarity(torch.tensor(forward_states[0][0]), torch.tensor(recovered_states[0][0]))\n",
        "    c_sim = F.cosine_similarity(torch.tensor(forward_states[0][1]), torch.tensor(recovered_states[0][1]))\n",
        "\n",
        "    return h_diff.item(), c_diff.item(), h_sim, c_sim\n",
        "\n",
        "input_size = 5\n",
        "hidden_size = 16\n",
        "batch_size = 4\n",
        "\n",
        "seq_lengths = [1, 2, 5, 10, 20, 50]\n",
        "results = {}\n",
        "\n",
        "print(\"Testing approximate reversibility over different sequence lengths:\")\n",
        "for seq_len in seq_lengths:\n",
        "    h_diff, c_diff, h_sim, c_sim = test_reversibility_for_seq_length(seq_len, input_size, hidden_size, batch_size)\n",
        "    results[seq_len] = (h_diff, c_diff)\n",
        "    print(f\"Sequence Length: {seq_len:2d}  -  Hidden Diff: {h_diff:.6f}, Cell Diff: {c_diff:.6f}\")\n",
        "    print(f\"Cosine similarities for length {seq_len:2d}: Hidden: {h_sim}, Cell: {c_sim}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9kw8V-zlMVn"
      },
      "source": [
        "As you can see, things get pretty dicey around 20 or so. It seems to do a\n",
        "\n",
        "decent enough job of reversibly computing hidden states over about 10 timesteps."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
